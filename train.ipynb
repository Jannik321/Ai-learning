{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5bb383a2",
   "metadata": {},
   "source": [
    "# Mask R-CNN 训练与推理流程代码解析\n",
    "## 1. 导入包"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a39bfa49",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "import torchvision  # 计算机视觉工具包，含模型和数据增强\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.models.detection import maskrcnn_resnet50_fpn  # Mask R-CNN 检测模型\n",
    "from torchvision.transforms import functional as F  # 图像变换函数\n",
    "import torchvision.transforms as T # 图像预处理与增强\n",
    "from pycocotools.coco import COCO  # COCO 数据集解析工具\n",
    "from PIL import Image  # 图像读取与处理\n",
    "from sklearn.metrics import precision_score, recall_score  # 精度与召回率评估指标"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5948b5ac",
   "metadata": {},
   "source": [
    "## 2. 自定义 COCO 数据集类"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfaaea5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "coco = COCO('数据/data/coco_data/coco2017/annotations/instances_train2017.json')\n",
    "\n",
    "# 查看图片ID列表\n",
    "print(\"图片ID列表:\", coco.getImgIds()[:5])\n",
    "\n",
    "# 获取键\n",
    "keys = list(coco.imgs.keys())\n",
    "print('键名:', keys[:5])\n",
    "\n",
    "# 查看类别信息\n",
    "print(\"类别信息:\", coco.loadCats(coco.getCatIds()))\n",
    "\n",
    "# 查看某张图片的信息\n",
    "img_id = coco.getImgIds()[0]\n",
    "print(\"图片信息:\", coco.loadImgs(img_id))\n",
    "\n",
    "# 查看某张图片的标注ID\n",
    "ann_ids = coco.getAnnIds(imgIds=img_id)\n",
    "print(\"标注ID:\", ann_ids)\n",
    "\n",
    "# 查看某个标注的内容\n",
    "if ann_ids:\n",
    "    ann = coco.loadAnns([ann_ids[0]])[0]\n",
    "    print(\"标注内容:\", ann)\n",
    "    # 探索 annToMask 的功能：将标注转换为二值掩码（mask）\n",
    "    mask = coco.annToMask(ann)\n",
    "    print(\"annToMask 输出掩码 shape:\", mask.shape)\n",
    "    print(\"掩码像素值统计:\", np.unique(mask, return_counts=True))\n",
    "\n",
    "# 探索 img 的功能：读取并显示图片\n",
    "img_path = coco.loadImgs(img_id)[0]['file_name']\n",
    "img_path = os.path.join('数据/data/coco_data/coco2017/train2017/train2017', img_path)\n",
    "img = Image.open(img_path).convert('RGB') # 读取图片并转换为RGB格式\n",
    "# img.show()  # 显示图片\n",
    "print(\"图片尺寸:\", img.size)\n",
    "\n",
    "# imgs 字典结构\n",
    "print(\"imgs 字典类型:\", type(coco.imgs))\n",
    "print(\"imgs 字典样例:\", list(coco.imgs.items())[:1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "122f96d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CocoDataset(torch.utils.data.Dataset):\n",
    "    \"\"\"\n",
    "    CocoDataset 是一个用于加载 COCO 格式数据集的自定义 PyTorch Dataset 类\n",
    "    支持实例分割任务，能够返回图像、目标框、类别标签、分割掩码等信息\n",
    "    \"\"\"\n",
    "    def __init__(self, root, annFile, transforms=None):\n",
    "        \"\"\"\n",
    "        参数:\n",
    "            root (str): 图像文件夹的根目录\n",
    "            annFile (str): COCO格式的标注文件路径\n",
    "            transforms (callable, optional): 图像及目标的变换函数\n",
    "        \"\"\"\n",
    "        self.root = root # 图像所在的根目录\n",
    "        self.coco = COCO(annFile) # 加载 COCO 数据集标注文件\n",
    "        self.ids = list(self.coco.imgs.keys()) # 获取所有图片的ID（self.ids 是图片的唯一标识符列表，每个元素对应一张图片）\n",
    "        self.transforms = transforms # 图像变换函数\n",
    "\n",
    "        # 只保留感兴趣的类别\n",
    "        self.target_cat_ids = [1, 2, 3, 4, 6, 7, 8]  # 行人和车辆\n",
    "        # 建立类别id到label的映射：1=行人, 2=车辆\n",
    "        self.cat_id_to_label = {1: 1}\n",
    "        for cid in [2, 3, 4, 6, 7, 8]:\n",
    "            self.cat_id_to_label[cid] = 2\n",
    "        self.num_classes = 3  # 0=背景, 1=行人, 2=车辆\n",
    "\n",
    "        # 区别说明：\n",
    "        # self.ids 保存的是图片ID列表，用于索引和遍历数据集中的每一张图片。\n",
    "        # cat_ids 保存的是类别ID列表，用于类别标签的映射和模型输出的类别数设置。\n",
    "        # 两者分别对应“图片”和“类别”两个不同的维度。\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        \"\"\"\n",
    "        根据索引 index 返回一张图片及其对应的目标信息（boxes、labels、masks 等）。\n",
    "        包括以下步骤：\n",
    "        1. 获取图片ID和对应的标注信息；\n",
    "        2. 读取图片文件并转换为RGB格式；\n",
    "        3. 提取每个目标的边界框、类别标签和分割掩码；\n",
    "        4. 将所有目标信息转换为Tensor格式，并组装为target字典；\n",
    "        5. 对图片进行变换；\n",
    "        6. 返回处理后的图片和target字典。\n",
    "        \"\"\"\n",
    "        coco = self.coco # 获取 COCO 实例\n",
    "        img_id = self.ids[index] # 根据索引获取图片ID\n",
    "        ann_ids = coco.getAnnIds(imgIds=img_id) # 获取该图片的标注ID\n",
    "        anns = coco.loadAnns(ann_ids) # 加载标注信息\n",
    "        anns = [ann for ann in anns if ann['category_id'] in self.target_cat_ids] # 过滤行人与车辆类别的标注信息\n",
    "        if len(anns) == 0: # 如果没有标注信息，递归调用下一个索引\n",
    "            return self.__getitem__((index + 1) % len(self.ids))\n",
    "        \n",
    "        path = coco.loadImgs(img_id)[0]['file_name'] # 获取图片文件名\n",
    "        img_path = os.path.join(self.root, path) # 构建图片完整路径\n",
    "        img = Image.open(img_path).convert('RGB') # 读取图片并转换为RGB格式\n",
    "        \n",
    "        boxes = [] # 存储目标边界框\n",
    "        labels = [] # 存储目标类别标签\n",
    "        masks = [] # 存储目标分割掩码\n",
    "        for ann in anns:\n",
    "            bbox = ann['bbox'] # 获取目标的边界框信息\n",
    "            # COCO 的 bbox 格式为 [x, y, width, height]，转换为 [x1, y1, x2, y2]\n",
    "            # 其中 (x1, y1) 是左上角坐标，(x2, y2) 是右下角坐标\n",
    "            boxes.append([bbox[0], bbox[1], bbox[0]+bbox[2], bbox[1]+bbox[3]])\n",
    "\n",
    "            labels.append(self.cat_id_to_label[ann['category_id']]) # 获取目标的类别标签，并映射到自定义的标签\n",
    "            mask = coco.annToMask(ann) # 获取目标的分割掩码\n",
    "            masks.append(mask) # 将掩码添加到列表中\n",
    "        # 将 boxes、labels 和 masks 转换为 Tensor 格式\n",
    "        boxes = torch.as_tensor(boxes, dtype=torch.float32)\n",
    "        labels = torch.as_tensor(labels, dtype=torch.int64)\n",
    "        masks = torch.as_tensor(np.stack(masks), dtype=torch.uint8)\n",
    "        image_id = torch.tensor([img_id])\n",
    "        area = torch.as_tensor([ann['area'] for ann in anns], dtype=torch.float32)\n",
    "        iscrowd = torch.as_tensor([ann.get('iscrowd', 0) for ann in anns], dtype=torch.int64)\n",
    "        \n",
    "        target = {} # 创建一个字典来存储目标信息\n",
    "        target['boxes'] = boxes \n",
    "        target['labels'] = labels\n",
    "        target['masks'] = masks\n",
    "        target['image_id'] = image_id\n",
    "        target['area'] = area\n",
    "        target['iscrowd'] = iscrowd\n",
    "\n",
    "        if self.transforms: # 如果定义了图像变换函数，则对图像进行变换\n",
    "            img = self.transforms(img)\n",
    "        else: # 否则直接转换为Tensor格式\n",
    "            img = F.to_tensor(img)\n",
    "        return img, target\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "566b6679",
   "metadata": {},
   "source": [
    "### 3. 数据增强与 DataLoader 构建\n",
    "\n",
    "本部分主要包括两项内容：\n",
    "\n",
    "**1. 数据增强（transform）**  \n",
    "- 通过 `get_transform()` 函数定义图像的预处理和增强操作。\n",
    "- 目前代码只包含 `ToTensor()`，即将 PIL 图像转换为 PyTorch Tensor，像素归一化到 [0,1]。\n",
    "- 数据增强的目的是提升模型的泛化能力，常见方法有：随机水平翻转、随机裁剪、颜色抖动、缩放等。\n",
    "\n",
    "**2. DataLoader 构建**  \n",
    "- 利用 PyTorch 的 `DataLoader` 对自定义的 `CocoDataset` 进行批量加载和并行加速。\n",
    "- `collate_fn` 用于处理不同图片目标数量不一致的情况，保证每个 batch 能正确组装成模型输入格式。\n",
    "- 这样可以高效地将数据送入模型进行训练或推理。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d40991d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def get_transform():\n",
    "#     # 这里只做了最基础的 ToTensor，可以根据需要添加更多增强\n",
    "#     return torchvision.transforms.Compose([\n",
    "#         torchvision.transforms.ToTensor()\n",
    "#     ])\n",
    "\n",
    "def get_transform(train=True):\n",
    "    \"\"\"\n",
    "    定义数据增强与预处理流程。\n",
    "    参数:\n",
    "        train (bool): 是否为训练模式。训练模式下会添加数据增强操作。\n",
    "    返回:\n",
    "        transforms (Compose): 图像变换操作的组合。\n",
    "    \"\"\"\n",
    "    transforms = []\n",
    "    # 基础转换：将PIL图像转换为Tensor，并归一化到[0,1]\n",
    "    transforms.append(T.ToTensor())\n",
    "    if train:\n",
    "        # 随机水平翻转，概率为0.5\n",
    "        transforms.append(T.RandomHorizontalFlip(0.5))\n",
    "        # 随机颜色抖动（亮度、对比度、饱和度、色调）\n",
    "        transforms.append(T.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1))\n",
    "        # 随机仿射变换（旋转、平移、缩放）\n",
    "        transforms.append(T.RandomAffine(degrees=10, translate=(0.05, 0.05), scale=(0.95, 1.05)))\n",
    "    return T.Compose(transforms)\n",
    "\n",
    "def collate_fn(batch):\n",
    "    # 假设 batch 是一个列表，每个元素是 (img, target)，比如 batch = [(img1, target1), (img2, target2), ...]\n",
    "    # zip(*batch) 的作用是把 batch 拆成两个元组：所有 img 和所有 target。\n",
    "    # 这样返回的就是 (imgs, targets)，imgs 是一个元组，targets 也是一个元组。\n",
    "    \n",
    "    # 因此，我们也可以这么写：\n",
    "    # imgs, targets = zip(*batch)\n",
    "    # return imgs, targets\n",
    "    return tuple(zip(*batch))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "748fe11b",
   "metadata": {},
   "source": [
    "为什么需要自定义？\n",
    "\n",
    "Mask R-CNN 任务中，每张图片的目标数量不同，target 字典的长度不一致。\n",
    "PyTorch 默认的 collate_fn 会尝试把 batch 里的 target 合并成一个大 tensor，这会报错（因为每张图片的目标数不同，无法直接拼接）。  \n",
    "如果没有这段函数：  \n",
    "\n",
    "DataLoader 会用默认的拼接方式，导致报错：  \n",
    "“TypeError: batch must contain tensors, numpy arrays, numbers, dicts or lists; found ...”  \n",
    "训练和推理都无法正常进行。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c543490",
   "metadata": {},
   "source": [
    "## 4. 模型构建与训练主流程（只跑一个batch理解代码结构）\n",
    "这里模型的建立与训练流程如下：\n",
    "1. 构建 Mask R-CNN 模型：maskrcnn_resnet50_fpn(num_classes=...)\n",
    "   - 该函数默认会加载在 COCO 数据集上预训练的权重（backbone 和检测头都初始化为预训练参数）。\n",
    "   - 只需指定 num_classes（包括背景），模型最后的分类头会根据类别数自动调整。\n",
    "2. 将模型移动到 GPU 或 CPU。\n",
    "3. 定义优化器 optimizer，通常只优化 requires_grad=True 的参数。\n",
    "4. 在训练循环中，前向传播计算损失，反向传播并更新参数。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4740f1ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train():\n",
    "    \"\"\"\n",
    "    训练主流程函数，包含以下步骤：\n",
    "    1. 设置训练和验证数据集的路径。\n",
    "    2. 构建训练和验证集的 Dataset 与 DataLoader。\n",
    "    3. 初始化 Mask R-CNN 模型，并设置类别数。\n",
    "    4. 配置优化器（SGD）。\n",
    "    5. 进入训练模式，进行训练\n",
    "    \"\"\"\n",
    "    # 路径设置\n",
    "    base_dir = os.path.dirname(os.path.abspath('mask_rcnn_train.py'))\n",
    "    train_img_dir = os.path.join(base_dir, '数据', 'data', 'coco_data', 'coco2017', 'train2017', 'train2017')\n",
    "    train_ann_file = os.path.join(base_dir, '数据', 'data', 'coco_data', 'coco2017', 'annotations', 'instances_train2017.json')\n",
    "     \n",
    "    # 创建数据集与Dataloader\n",
    "    train_dataset = CocoDataset(root=train_img_dir, annFile=train_ann_file, transforms=get_transform())\n",
    "    train_loader = DataLoader(train_dataset, batch_size=2, shuffle=True, num_workers=2, collate_fn=collate_fn)\n",
    "  \n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    model = maskrcnn_resnet50_fpn(num_classes=train_dataset.num_classes)\n",
    "    model.to(device)\n",
    "    params = [p for p in model.parameters() if p.requires_grad]\n",
    "\n",
    "    # 使用预训练模型的参数\n",
    "    optimizer = torch.optim.SGD(params, lr=0.0005, momentum=0.9, weight_decay=0.0005)\n",
    "\n",
    "    # 只跑一个batch\n",
    "    # 进入训练模式，仅跑一个 batch 理解流程\n",
    "    model.train()\n",
    "    for images, targets in train_loader:\n",
    "        # 将图片和目标信息移动到指定设备上\n",
    "        images = [img.to(device) for img in images]\n",
    "        targets = [{k: v.to(device) for k, v in t.items()} for t in targets]\n",
    "        # 前向传播，计算损失字典（包含分类、框回归、掩码等多项损失）\n",
    "        loss_dict = model(images, targets)\n",
    "        losses = sum(loss for loss in loss_dict.values()) # 将所有损失项加和得到总损失\n",
    "        optimizer.zero_grad() # 梯度清零\n",
    "        losses.backward() # 反向传播\n",
    "        optimizer.step() # 优化器更新参数\n",
    "        # 打印当前 batch 的损失\n",
    "        print(f'单batch Loss: {losses.item():.4f}')\n",
    "        break  # 只跑一个 batch，便于调试和理解流程\n",
    "\n",
    "    # # 完整训练流程\n",
    "    # num_epochs = 10\n",
    "    # for epoch in range(num_epochs):\n",
    "    #     model.train()\n",
    "    #     epoch_loss = 0\n",
    "    #     for images, targets in train_loader:\n",
    "    #         images = [img.to(device) for img in images]\n",
    "    #         targets = [{k: v.to(device) for k, v in t.items()} for t in targets]\n",
    "    #         loss_dict = model(images, targets)\n",
    "    #         losses = sum(loss for loss in loss_dict.values())\n",
    "    #         optimizer.zero_grad()\n",
    "    #         losses.backward()\n",
    "    #         optimizer.step()\n",
    "    #         epoch_loss += losses.item()\n",
    "    #     print(f'Epoch {epoch+1}/{num_epochs}, Loss: {epoch_loss/len(train_loader):.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fc6c250",
   "metadata": {},
   "outputs": [],
   "source": [
    "train()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ad6745d",
   "metadata": {},
   "source": [
    "## 5. 验证与评估流程"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa8bc267",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
